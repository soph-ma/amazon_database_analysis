{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains topic modelling for positive and negative reviews. I have created a separate model defining 10 possible topics for each of these catagories as well as giving the probable words covered by each topic. \n",
    "\n",
    "This is used to show what is common for positive reviews, and what is common for negative ones. Looking at separate words under each topic, we can see what users pay attention to when leaving a negative or a positive comment; what is important for them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "W4XNiqRquFXr"
   },
   "outputs": [],
   "source": [
    "file = \"Cell_Phones_&_Accessories.txt\"\n",
    "f_hand = open(file, \"r+\", encoding=\"UTF-8\")\n",
    "contents = f_hand.readlines()\n",
    "# group each review separately in a list inside a larger list of reviews\n",
    "contents = [contents[x:x+11] for x in range(0, len(contents), 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split reviews into positive and negative. I didn't take into account the reviews with score 3.0 because they are neutral\n",
    "pos_revs = []\n",
    "neg_revs = []\n",
    "for rev in contents:\n",
    "    if \"review/score: 1.0\\n\" in rev or \"review/score: 2.0\\n\" in rev:\n",
    "        neg_revs.append(rev)\n",
    "    elif \"review/score: 4.0\\n\" in rev or \"review/score: 5.0\\n\" in rev:\n",
    "        pos_revs.append(rev)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "def get_data(revs):\n",
    "    new_revs = [rev[9] for rev in revs] # line 9 contains the text of the review\n",
    "    processed = []\n",
    "    for rev in new_revs:\n",
    "        # remove stopwords, make lowercase and remove if not an alphabetical symbol\n",
    "        rev = [w.lower() for w in rev[12:].split() if w.isalpha() and w not in stop_words]\n",
    "        processed.append(rev)\n",
    "    return(processed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the previous function to pos and neg reviews separately\n",
    "pos_revs = get_data(pos_revs) \n",
    "neg_revs = get_data(neg_revs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['great', 'tried', 'others', 'ten', 'compared', 'real', 'easy', 'use', 'definite', 'recommended', 'buy', 'transfer', 'data']\n",
      "['first', 'company', 'took', 'money', 'sent', 'email', 'telling', 'product', 'a', 'week', 'half', 'later', 'i', 'received', 'another', 'email', 'telling', 'actually', 'i', 'received', 'email', 'telling', 'i', 'finally', 'got', 'money', 'i', 'went', 'another', 'company', 'buy', 'product', 'work', 'even', 'though', 'depicts', 'i', 'sent', 'numerous', 'emails', 'company', 'i', 'actually', 'find', 'phone', 'number', 'website', 'i', 'still', 'gotten', 'kind', 'what', 'kind', 'customer', 'service', 'no', 'one', 'help', 'my', 'advice', 'waste']\n"
     ]
    }
   ],
   "source": [
    "print(pos_revs[0])\n",
    "print(neg_revs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create bags of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's firstly create a dictionary\n",
    "def get_all(pos, neg):\n",
    "    # unite all processed reviews  \n",
    "    all_words = []\n",
    "    for rev in pos:\n",
    "        all_words.append(rev)\n",
    "    for rev in neg:\n",
    "        all_words.append(rev)\n",
    "    return(all_words)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['great', 'tried', 'others', 'ten', 'compared', 'real', 'easy', 'use', 'definite', 'recommended', 'buy', 'transfer', 'data'], ['works', 'real', 'little', 'hard', 'set', 'part', 'doesnt', 'work', 'thru', 'handset', 'manager', 'go', 'networking', 'turn'], ['the', 'price', 'right', 'cable', 'compared', 'sony', 'ericssons', 'offering', 'there', 'different', 'prices', 'amazon', 'make', 'sure', 'get', 'i', 'popped', 'cd', 'followed', 'line', 'instruction', 'file', 'disk', 'phone', 'started', 'if', 'similar', 'problem', 'may', 'try', 'i', 'previously', 'installed', 'variety', 'downloadable', 'software', 'it', 'took', 'minutes', 'fumbling', 'i', 'made', 'way', 'phone', 'monitor', 'options', 'opening', 'phone', 'from', 'window', 'hit', 'options', 'there', 'may', 'better', 'way', 'get', 'i', 'go', 'com', 'ports', 'tab', 'enable', 'com', 'it', 'told', 'wouldnt', 'enable', 'ir', 'within', 'phone', 'presumably', 'one', 'remaining', 'i', 'may', 'issue', 'i', 'installed', 'software', 'fresh', 'i', 'previously', 'using', 'ir', 'feature', 'transfer', 'the', 'cable', 'faster', 'the', 'big', 'benefit', 'dont', 'worry', 'losing', 'line', 'site', 'messing'], ['much', 'say', 'data', 'cable', 'works', 'i', 'able', 'transfer', 'files', 'phone', 'pc'], ['i', 'sony', 'ericsson', 'sell', 'i', 'received', 'usb', 'data', 'cable', 'i', 'troubles', 'installing', 'soon', 'resolved', 'i', 'worked', 'pleased', 'purchase', 'would', 'highly', 'recommend', 'product', 'mynetdeals', 'really', 'big', 'save', 'buying', 'direct', 'sony'], ['this', 'good', 'cable', 'you', 'need', 'subscribe', 'data', 'service', 'pictures', 'ringtones', 'this', 'cable', 'pays', 'one'], ['this', 'cable', 'saves', 'lot', 'i', 'need', 'buy', 'stuff', 'online', 'i', 'download', 'straight', 'makes', 'easy', 'transfer', 'ring', 'contact', 'it', 'great', 'put', 'things', 'also', 'great', 'keeping', 'back'], ['a', 'great', 'i', 'use', 'nokia', 'use', 'i', 'hear', 'songs', 'waste', 'call', 'low', 'not', 'loud', 'ipod', 'very', 'great', 'singal', 'looking', 'hearing', 'songs', 'phone', 'watch', 'compatible', 'hear', 'music', 'i', 'tried', 'i', 'able', 'use', 'regular', 'bluetooth', 'i', 'could', 'hear', 'music', 'gurantee'], ['gone', 'many', 'different', 'bluetooth', 'this', 'first', 'pair', 'i', 'ever', 'bought', 'many', 'many', 'years', 'wearing', 'right', 'tried', 'jabra', 'jabra', 'arctic', 'that', 'even', 'include', 'plain', 'old', 'look', 'my', 'wife', 'hates', 'they', 'still', 'gold', 'walk', 'kills', 'bt', 'reception', 'every', 'time', 'every', 'these', 'lose', 'signal', 'half', 'the', 'jabra', 'even', 'work', 'set', 'table', 'front', 'the', 'arctic', 'cooling', 'headphones', 'they', 'still', 'lose', 'signal', 'whenever', 'i', 'walk', 'i', 'live', 'next', 'cell', 'so', 'situation', 'stressful', 'bt', 'headphone', 'the', 'old'], ['review', 'years', 'worked', 'great', 'i', 'you', 'look', 'like', 'complete', 'dork', 'product', 'archaic']]\n"
     ]
    }
   ],
   "source": [
    "all_words = get_all(pos_revs, neg_revs)\n",
    "print(all_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary\n",
    "dictionary = gensim.corpora.Dictionary(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bags of words for each set of reviews\n",
    "dic_pos = [dictionary.doc2bow(rev) for rev in pos_revs[:10000]]\n",
    "dic_neg = [dictionary.doc2bow(rev) for rev in neg_revs[:10000]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics in positive reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running LDA for positive reviews\n",
    "lda_model = gensim.models.ldamodel.LdaModel(dic_pos, \n",
    "                                           id2word = dictionary,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=100, \n",
    "                                           update_every=1, \n",
    "                                           chunksize=100, \n",
    "                                           passes=10, \n",
    "                                           alpha=\"auto\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.046*\"around\" + 0.031*\"card\" + 0.028*\"hours\" + 0.021*\"open\" + 0.020*\"palm\" + 0.020*\"access\" + 0.016*\"simply\" + 0.016*\"to\" + 0.015*\"deal\" + 0.014*\"is\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.094*\"i\" + 0.040*\"phone\" + 0.024*\"the\" + 0.014*\"one\" + 0.013*\"battery\" + 0.013*\"great\" + 0.013*\"it\" + 0.011*\"this\" + 0.011*\"good\" + 0.010*\"use\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.079*\"service\" + 0.044*\"pictures\" + 0.043*\"fine\" + 0.036*\"ringtones\" + 0.036*\"charging\" + 0.028*\"range\" + 0.020*\"live\" + 0.017*\"thank\" + 0.013*\"sending\" + 0.012*\"none\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.051*\"download\" + 0.029*\"online\" + 0.019*\"u\" + 0.018*\"stuff\" + 0.018*\"notice\" + 0.018*\"lock\" + 0.013*\"hardly\" + 0.012*\"straight\" + 0.008*\"saves\" + 0.005*\"smallest\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.024*\"cell\" + 0.020*\"screen\" + 0.019*\"camera\" + 0.017*\"phones\" + 0.015*\"long\" + 0.014*\"voice\" + 0.012*\"features\" + 0.012*\"car\" + 0.012*\"button\" + 0.010*\"hard\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.028*\"delivery\" + 0.009*\"anymore\" + 0.008*\"nicer\" + 0.000*\"outbound\" + 0.000*\"fone\" + 0.000*\"schwarzenegger\" + 0.000*\"arnold\" + 0.000*\"reverse\" + 0.000*\"hitch\" + 0.000*\"althiough\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.056*\"headset\" + 0.028*\"ear\" + 0.021*\"jabra\" + 0.021*\"volume\" + 0.017*\"fit\" + 0.015*\"reception\" + 0.014*\"look\" + 0.012*\"ever\" + 0.011*\"cover\" + 0.011*\"wear\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.085*\"case\" + 0.033*\"verizon\" + 0.030*\"color\" + 0.028*\"dropped\" + 0.025*\"year\" + 0.025*\"cingular\" + 0.024*\"although\" + 0.024*\"clip\" + 0.016*\"belt\" + 0.014*\"plastic\"\n",
      "\n",
      "\n",
      "Topic: 8 \n",
      "Words: 0.037*\"oem\" + 0.025*\"seller\" + 0.022*\"amazing\" + 0.019*\"paying\" + 0.012*\"definately\" + 0.011*\"described\" + 0.011*\"skin\" + 0.009*\"complete\" + 0.008*\"beats\" + 0.006*\"contacted\"\n",
      "\n",
      "\n",
      "Topic: 9 \n",
      "Words: 0.043*\"minor\" + 0.031*\"other\" + 0.028*\"cord\" + 0.022*\"cradle\" + 0.018*\"cellular\" + 0.016*\"average\" + 0.014*\"provider\" + 0.004*\"screw\" + 0.000*\"sorta\" + 0.000*\"managable\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible topics(=reasons for positive comments) deduced by me from words:\n",
    "\n",
    "1) simplicity and accessibility\n",
    "2) battery life\n",
    "3) pictures and ringtones\n",
    "4) cool staff that can be downloaded\n",
    "5) good camera\n",
    "6) fast delivery\n",
    "7) general look\n",
    "8) good case quality\n",
    "9) managable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics in negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model2 = gensim.models.ldamodel.LdaModel(dic_neg, \n",
    "                                           id2word = dictionary,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=100, \n",
    "                                           update_every=1, \n",
    "                                           chunksize=100, \n",
    "                                           passes=10, \n",
    "                                           alpha=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.048*\"usb\" + 0.046*\"clip\" + 0.043*\"case\" + 0.033*\"palm\" + 0.027*\"feature\" + 0.026*\"belt\" + 0.017*\"speak\" + 0.016*\"luck\" + 0.013*\"holster\" + 0.012*\"heavy\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.035*\"the\" + 0.021*\"headset\" + 0.017*\"it\" + 0.015*\"use\" + 0.014*\"ear\" + 0.013*\"good\" + 0.013*\"like\" + 0.012*\"sound\" + 0.012*\"this\" + 0.012*\"bluetooth\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.126*\"i\" + 0.045*\"phone\" + 0.016*\"one\" + 0.014*\"would\" + 0.014*\"get\" + 0.011*\"battery\" + 0.008*\"work\" + 0.008*\"even\" + 0.008*\"time\" + 0.008*\"bought\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.034*\"software\" + 0.032*\"music\" + 0.019*\"computer\" + 0.014*\"dont\" + 0.013*\"needs\" + 0.013*\"issue\" + 0.012*\"windows\" + 0.012*\"iphone\" + 0.011*\"itunes\" + 0.010*\"internet\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.058*\"verizon\" + 0.040*\"treo\" + 0.033*\"card\" + 0.025*\"contact\" + 0.021*\"all\" + 0.018*\"sim\" + 0.016*\"pink\" + 0.013*\"keyboard\" + 0.012*\"add\" + 0.012*\"options\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.032*\"remove\" + 0.024*\"rating\" + 0.024*\"accessories\" + 0.007*\"glove\" + 0.000*\"flipper\" + 0.000*\"linksys\" + 0.000*\"remembered\" + 0.000*\"occurs\" + 0.000*\"retired\" + 0.000*\"silicon\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.065*\"person\" + 0.052*\"difficult\" + 0.041*\"reason\" + 0.037*\"wireless\" + 0.023*\"while\" + 0.020*\"based\" + 0.016*\"interface\" + 0.014*\"ability\" + 0.013*\"gives\" + 0.012*\"too\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.039*\"poorly\" + 0.027*\"paired\" + 0.014*\"tip\" + 0.013*\"house\" + 0.010*\"tips\" + 0.010*\"has\" + 0.009*\"disapointed\" + 0.008*\"spring\" + 0.006*\"includes\" + 0.000*\"slid\"\n",
      "\n",
      "\n",
      "Topic: 8 \n",
      "Words: 0.041*\"rather\" + 0.031*\"fully\" + 0.014*\"htc\" + 0.011*\"loses\" + 0.007*\"recognized\" + 0.005*\"an\" + 0.004*\"factory\" + 0.000*\"cradles\" + 0.000*\"kindle\" + 0.000*\"mybat\"\n",
      "\n",
      "\n",
      "Topic: 9 \n",
      "Words: 0.040*\"compatible\" + 0.028*\"is\" + 0.028*\"description\" + 0.026*\"purchasing\" + 0.013*\"sets\" + 0.009*\"ahead\" + 0.009*\"gift\" + 0.000*\"sf\" + 0.000*\"reformat\" + 0.000*\"aid\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model2.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible topics(=reasons for negative comments) deduced by me from words covered by topics:\n",
    "\n",
    "1) too heavy\n",
    "2) bad battery \n",
    "3) issues with software and complicated interface\n",
    "4) accessories that are difficult to remove?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "topic_modelling",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
